{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pyswarms as ps\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import offsetbox\n",
    "from time import time\n",
    "from PIL import Image\n",
    "import glob\n",
    "import re\n",
    "from struct import *\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from deap import creator, base, tools, algorithms\n",
    "import sys\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "(10000,)\n",
      "(5000, 784)\n",
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "path_dataset_save = 'MNIST/10000Train_5000Test/'\n",
    "file = open(path_dataset_save+'X_train_picked.pckl','rb')\n",
    "X_train = pickle.load(file); file.close()\n",
    "file = open(path_dataset_save+'y_train_picked.pckl','rb')\n",
    "y_train = pickle.load(file); file.close()\n",
    "file = open(path_dataset_save+'X_test_picked.pckl','rb')\n",
    "X_test = pickle.load(file); file.close()\n",
    "file = open(path_dataset_save+'y_test_picked.pckl','rb')\n",
    "y_test = pickle.load(file); file.close()\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg(l):\n",
    "    \"\"\"\n",
    "    Returns the average between list elements\n",
    "    \"\"\"\n",
    "    return (sum(l)/float(len(l)))\n",
    "\n",
    "\n",
    "def getFitness(individual, X, y):\n",
    "    \"\"\"\n",
    "    Feature subset fitness function\n",
    "    \"\"\"\n",
    "\n",
    "    if(individual.count(0) != len(individual)):\n",
    "        # get index with value 0\n",
    "        cols = [index for index in range(\n",
    "            len(individual)) if individual[index] == 0]\n",
    "\n",
    "        # get features subset\n",
    "        X_parsed = X.drop(X.columns[cols], axis=1)\n",
    "        X_subset = pd.get_dummies(X_parsed)\n",
    "\n",
    "        # apply classification algorithm\n",
    "        #clf = LogisticRegression()\n",
    "        clf = GaussianNB()\n",
    "        #clf.fit(X_subset, y)\n",
    "        #return accuracy_score(y, clf.predict(X_subset), normalize = True)\n",
    "        return (avg(cross_val_score(clf, X_subset, y, cv=2)),)\n",
    "    else:\n",
    "        return(0,)\n",
    "\n",
    "\n",
    "def geneticAlgorithm(X, y, n_population, n_generation):\n",
    "    \"\"\"\n",
    "    Deap global variables\n",
    "    Initialize variables to use eaSimple\n",
    "    \"\"\"\n",
    "    # create individual\n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "    # create toolbox\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "    toolbox.register(\"individual\", tools.initRepeat,\n",
    "                     creator.Individual, toolbox.attr_bool, len(X.columns))\n",
    "    toolbox.register(\"population\", tools.initRepeat, list,\n",
    "                     toolbox.individual)\n",
    "    toolbox.register(\"evaluate\", getFitness, X=X, y=y)\n",
    "    toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "    toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "    # initialize parameters\n",
    "    pop = toolbox.population(n=n_population)\n",
    "    hof = tools.HallOfFame(n_population * n_generation)\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"max\", np.max)\n",
    "\n",
    "    # genetic algorithm\n",
    "    pop, log = algorithms.eaSimple(pop, toolbox, cxpb=0.5, mutpb=0.2,\n",
    "                                   ngen=n_generation, stats=stats, halloffame=hof,\n",
    "                                   verbose=True)\n",
    "\n",
    "    # return hall of fame\n",
    "    return hof\n",
    "\n",
    "\n",
    "def bestIndividual(hof, X, y):\n",
    "    \"\"\"\n",
    "    Get the best individual\n",
    "    \"\"\"\n",
    "    maxAccurcy = 0.0\n",
    "    for individual in hof:\n",
    "        #print(individual.fitness.values)\n",
    "        #print(maxAccurcy)\n",
    "        if(individual.fitness.values[0] > maxAccurcy):\n",
    "            maxAccurcy = individual.fitness.values\n",
    "            _individual = individual\n",
    "\n",
    "    _individualHeader = [list(X)[i] for i in range(\n",
    "        len(_individual)) if _individual[i] == 1]\n",
    "    return _individual.fitness.values, _individual, _individualHeader\n",
    "\n",
    "\n",
    "def getArguments():\n",
    "    \"\"\"\n",
    "    Get argumments from command-line\n",
    "    If pass only dataframe path, pop and gen will be default\n",
    "    \"\"\"\n",
    "    dfPath = sys.argv[1]\n",
    "    if(len(sys.argv) == 4):\n",
    "        pop = int(sys.argv[2])\n",
    "        gen = int(sys.argv[3])\n",
    "    else:\n",
    "        pop = 10\n",
    "        gen = 2\n",
    "    return dfPath, pop, gen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\tavg     \tmin     \tmax     \n",
      "0  \t30    \t0.584475\t0.536192\t0.629086\n",
      "1  \t16    \t0.600449\t0.572493\t0.638484\n",
      "2  \t25    \t0.614504\t0.591491\t0.641785\n",
      "3  \t22    \t0.625491\t0.601089\t0.649886\n",
      "4  \t22    \t0.633037\t0.601288\t0.656388\n",
      "5  \t16    \t0.644503\t0.61859 \t0.658586\n",
      "6  \t19    \t0.648757\t0.615492\t0.658586\n",
      "7  \t23    \t0.654367\t0.638988\t0.667488\n",
      "8  \t23    \t0.657817\t0.640288\t0.667488\n",
      "9  \t17    \t0.660267\t0.639589\t0.667686\n",
      "10 \t23    \t0.662537\t0.647389\t0.676892\n",
      "11 \t23    \t0.664364\t0.632693\t0.676892\n",
      "12 \t13    \t0.668829\t0.634192\t0.68289 \n",
      "13 \t16    \t0.669186\t0.624689\t0.682989\n",
      "14 \t16    \t0.673957\t0.63369 \t0.682989\n",
      "15 \t18    \t0.676826\t0.652892\t0.683489\n",
      "16 \t9     \t0.68021 \t0.663293\t0.683489\n",
      "17 \t15    \t0.681753\t0.664787\t0.686489\n",
      "18 \t15    \t0.682239\t0.657689\t0.68869 \n",
      "19 \t22    \t0.680239\t0.629394\t0.69029 \n",
      "20 \t21    \t0.682386\t0.667492\t0.69029 \n",
      "Best Accuracy: \t(0.6902897504463601,)\n",
      "Number of Features in Subset: \t396\n",
      "Individual: \t\t[1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "Feature Subset\t: [0, 2, 3, 5, 7, 8, 9, 10, 12, 13, 14, 18, 20, 25, 27, 28, 30, 32, 33, 35, 36, 38, 40, 43, 44, 47, 48, 50, 52, 58, 60, 61, 62, 63, 68, 69, 70, 71, 72, 77, 79, 80, 83, 85, 86, 87, 90, 92, 96, 97, 100, 101, 102, 106, 107, 108, 109, 115, 116, 120, 122, 123, 125, 126, 127, 128, 133, 134, 136, 139, 140, 142, 143, 146, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 166, 167, 174, 177, 181, 183, 185, 186, 188, 189, 191, 193, 194, 196, 201, 202, 203, 204, 205, 210, 213, 214, 215, 216, 217, 219, 220, 221, 222, 228, 229, 231, 232, 233, 234, 235, 237, 241, 242, 247, 249, 252, 257, 258, 260, 262, 264, 267, 270, 272, 273, 275, 277, 280, 284, 289, 290, 292, 293, 297, 300, 302, 304, 306, 308, 309, 316, 317, 318, 321, 322, 323, 325, 326, 328, 329, 330, 333, 334, 335, 336, 339, 340, 341, 343, 346, 347, 349, 353, 355, 361, 362, 363, 364, 374, 375, 378, 380, 382, 384, 388, 389, 390, 394, 395, 399, 400, 403, 404, 405, 407, 408, 410, 412, 415, 416, 418, 424, 426, 429, 430, 431, 432, 433, 435, 437, 440, 441, 443, 445, 447, 449, 452, 453, 454, 458, 459, 461, 463, 464, 466, 468, 471, 473, 475, 476, 477, 479, 483, 485, 489, 490, 491, 493, 494, 495, 497, 498, 500, 501, 502, 503, 505, 506, 507, 509, 510, 513, 514, 515, 516, 517, 518, 519, 524, 525, 526, 527, 528, 529, 530, 533, 536, 537, 540, 542, 544, 545, 550, 551, 552, 554, 555, 556, 557, 559, 560, 561, 564, 568, 570, 579, 580, 582, 583, 585, 586, 588, 589, 590, 592, 593, 594, 595, 597, 602, 604, 606, 607, 608, 611, 612, 616, 619, 620, 622, 623, 625, 633, 634, 636, 643, 645, 646, 650, 655, 656, 657, 658, 660, 661, 664, 666, 667, 668, 670, 671, 672, 674, 675, 676, 677, 678, 679, 680, 681, 688, 691, 693, 694, 695, 696, 697, 698, 699, 701, 704, 706, 708, 710, 713, 714, 715, 716, 717, 718, 719, 723, 724, 728, 731, 732, 733, 735, 736, 739, 743, 747, 748, 749, 750, 751, 753, 754, 756, 757, 758, 759, 760, 762, 763, 766, 767, 770, 772, 773, 774, 775, 779]\n"
     ]
    }
   ],
   "source": [
    "hof = geneticAlgorithm(pd.DataFrame(X_train), y_train, 30, 20)\n",
    "accuracy, individual, header = bestIndividual(hof, pd.DataFrame(X_train), y_train)\n",
    "print('Best Accuracy: \\t' + str(accuracy))\n",
    "print('Number of Features in Subset: \\t' + str(individual.count(1)))\n",
    "print('Individual: \\t\\t' + str(individual))\n",
    "print('Feature Subset\\t: ' + str(header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected features = 396/784\n",
      "accuracy before FS = 53.5\n",
      "accuracy after FS = 61.8\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "print('selected features = ' + str(len(header)) + '/' + str(X_train.shape[1]))\n",
    "model.fit(X_train, y_train)\n",
    "print('accuracy before FS = ' + str(accuracy_score(y_test, model.predict(X_test), normalize = True)*100))\n",
    "X_subset = X_train[:,header]\n",
    "model.fit(X_subset, y_train)\n",
    "print('accuracy after FS = ' + str(accuracy_score(y_test, model.predict(X_test[:,header]), normalize = True)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
