{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "5G3CN0kCXQCI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "BpAxQHR0whS8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W1s4ADfTXQfe",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7f87d3b9-4dad-4917-baf7-4e7ba0db37c2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532347489015,
          "user_tz": 240,
          "elapsed": 1292,
          "user": {
            "displayName": "Maria Samad",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "104872086100477216762"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "!pip install mlxtend\n",
        "\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# choose a local (colab) directory to store the data.\n",
        "local_download_path = os.path.expanduser('~/data')\n",
        "try:\n",
        "  os.makedirs(local_download_path)\n",
        "except: pass\n",
        "\n",
        "# 2. Auto-iterate using the query syntax\n",
        "#    https://developers.google.com/drive/v2/web/search-parameters\n",
        "file_list = drive.ListFile(\n",
        "    {'q': \"'' in parents\"}).GetList()\n",
        "\n",
        "for f in file_list:\n",
        "  # 3. Create & download by id.\n",
        "  print('title: %s, id: %s' % (f['title'], f['id']))\n",
        "  fname = os.path.join(local_download_path, f['title'])\n",
        "  print('downloading to {}'.format(fname))\n",
        "  f_ = drive.CreateFile({'id': f['id']})\n",
        "  f_.GetContentFile(fname)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: fea.mat, id: 1StqL1hRrf4mmeOQPSaPzaAo-Q85bEkLj\n",
            "downloading to /content/data/fea.mat\n",
            "title: gnd.mat, id: 1Nc7cRji_5ds4_8cepgIcZIJL3J7eO2zv\n",
            "downloading to /content/data/gnd.mat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Sqr1zDHpWU1K",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "08f14eca-f6fb-4bb1-b1d3-07ac581f191f",
        "executionInfo": {
          "status": "error",
          "timestamp": 1532348277136,
          "user_tz": 240,
          "elapsed": 2407,
          "user": {
            "displayName": "Maria Samad",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "104872086100477216762"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import offsetbox\n",
        "from time import time\n",
        "from PIL import Image\n",
        "import glob\n",
        "import re\n",
        "from struct import *\n",
        "from skimage.transform import resize\n",
        "from sklearn.manifold import LocallyLinearEmbedding as LLE\n",
        "from sklearn.manifold import Isomap\n",
        "from sklearn.manifold import MDS\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import KernelPCA\n",
        "from sklearn.manifold import SpectralEmbedding as LaplacianEigenmap\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "#from supervised_PCA import Supervised_PCA as SPCA\n",
        "from sklearn.manifold import TSNE\n",
        "#from metric_learning_closed_form_efficient import Metric_learning_closed_form as ML\n",
        "#from kernel_FLDA_efficient import Kernel_FLDA     \n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "\n",
        "\n",
        "def main():\n",
        "    # ----- settings:\n",
        "    dataset = 'MNIST'    # --> 'Facial' or 'MNIST'\n",
        "    embedding_method = 'ML'\n",
        "    load_dataset_again = False\n",
        "    subset_of_MNIST = True\n",
        "    pick_subset_of_MNIST_again = False\n",
        "    MNIST_subset_cardinality_training = 10000   # picking from first samples of 60,000 samples\n",
        "    MNIST_subset_cardinality_testing = 5000  # picking from first samples of 10,000 samples\n",
        "    # ----- paths:\n",
        "    if dataset == 'Facial':\n",
        "        path_dataset = './input/att_database/'\n",
        "        path_dataset_save = './input/pickle_dataset/Facial/'\n",
        "    elif dataset == 'MNIST':\n",
        "        path_dataset = './input/mnist/'\n",
        "        path_dataset_save = '/content/data/'\n",
        "    # ----- Loading dataset:\n",
        "    print('Reading dataset...')\n",
        "    if dataset == 'MNIST':\n",
        "        if load_dataset_again:\n",
        "            training_data = list(read_MNIST_dataset(dataset = \"training\", path = path_dataset))\n",
        "            testing_data = list(read_MNIST_dataset(dataset = \"testing\", path = path_dataset))\n",
        "\n",
        "            number_of_training_samples = len(training_data)\n",
        "            dimension_of_data = 28 * 28\n",
        "            X_train = np.empty((0, dimension_of_data))\n",
        "            y_train = np.empty((0, 1))\n",
        "            for sample_index in range(number_of_training_samples):\n",
        "                if np.mod(sample_index, 1) == 0:\n",
        "                    print('sample ' + str(sample_index) + ' from ' + str(number_of_training_samples) + ' samples...')\n",
        "                label, pixels = training_data[sample_index]\n",
        "                pixels_reshaped = np.reshape(pixels, (1, 28*28))\n",
        "                X_train = np.vstack([X_train, pixels_reshaped])\n",
        "                y_train = np.vstack([y_train, label])\n",
        "            y_train = y_train.ravel()\n",
        "\n",
        "            number_of_testing_samples = len(testing_data)\n",
        "            dimension_of_data = 28 * 28\n",
        "            X_test = np.empty((0, dimension_of_data))\n",
        "            y_test = np.empty((0, 1))\n",
        "            for sample_index in range(number_of_testing_samples):\n",
        "                if np.mod(sample_index, 1) == 0:\n",
        "                    print('sample ' + str(sample_index) + ' from ' + str(number_of_testing_samples) + ' samples...')\n",
        "                label, pixels = testing_data[sample_index]\n",
        "                pixels_reshaped = np.reshape(pixels, (1, 28*28))\n",
        "                X_test = np.vstack([X_test, pixels_reshaped])\n",
        "                y_test = np.vstack([y_test, label])\n",
        "            y_test = y_test.ravel()\n",
        "\n",
        "            save_variable(X_train, 'X_train', path_to_save=path_dataset_save)\n",
        "            save_variable(y_train, 'y_train', path_to_save=path_dataset_save)\n",
        "            save_variable(X_test, 'X_test', path_to_save=path_dataset_save)\n",
        "            save_variable(y_test, 'y_test', path_to_save=path_dataset_save)\n",
        "#         else:\n",
        "#             file = open(path_dataset_save+'X_train.pckl','rb')\n",
        "#             X_train = pickle.load(file); file.close()\n",
        "#             file = open(path_dataset_save+'y_train.pckl','rb')\n",
        "#             y_train = pickle.load(file); file.close()\n",
        "#             file = open(path_dataset_save+'X_test.pckl','rb')\n",
        "#             X_test = pickle.load(file); file.close()\n",
        "#             file = open(path_dataset_save+'y_test.pckl','rb')\n",
        "#             y_test = pickle.load(file); file.close()\n",
        "\n",
        "        if subset_of_MNIST:\n",
        "            if pick_subset_of_MNIST_again:\n",
        "                X_train_picked = X_train[0:MNIST_subset_cardinality_training, :]\n",
        "                X_test_picked = X_test[0:MNIST_subset_cardinality_testing, :]\n",
        "                y_train_picked = y_train[0:MNIST_subset_cardinality_training]\n",
        "                y_test_picked = y_test[0:MNIST_subset_cardinality_testing]\n",
        "                save_variable(X_train_picked, 'X_train_picked', path_to_save=path_dataset_save)\n",
        "                save_variable(X_test_picked, 'X_test_picked', path_to_save=path_dataset_save)\n",
        "                save_variable(y_train_picked, 'y_train_picked', path_to_save=path_dataset_save)\n",
        "                save_variable(y_test_picked, 'y_test_picked', path_to_save=path_dataset_save)\n",
        "            else:\n",
        "                file = open(path_dataset_save+'X_train_picked.pckl','rb')\n",
        "                X_train_picked = pickle.load(file); file.close()\n",
        "                file = open(path_dataset_save+'X_test_picked.pckl','rb')\n",
        "                X_test_picked = pickle.load(file); file.close()\n",
        "                file = open(path_dataset_save+'y_train_picked.pckl','rb')\n",
        "                y_train_picked = pickle.load(file); file.close()\n",
        "                file = open(path_dataset_save+'y_test_picked.pckl','rb')\n",
        "                y_test_picked = pickle.load(file); file.close()\n",
        "            X_train = X_train_picked\n",
        "            X_test = X_test_picked\n",
        "            y_train = y_train_picked\n",
        "            y_test = y_test_picked\n",
        "\n",
        "        X = X_test\n",
        "        y = y_test\n",
        "        image_shape = (28, 28)\n",
        "    elif dataset == 'Facial':\n",
        "        if load_dataset_again:\n",
        "            X, y, image_shape = read_image_dataset(dataset_path=path_dataset, imagesType='.jpg')\n",
        "            save_variable(variable=X, name_of_variable='X', path_to_save=path_dataset_save)\n",
        "            save_variable(variable=y, name_of_variable='y', path_to_save=path_dataset_save)\n",
        "            save_variable(variable=image_shape, name_of_variable='image_shape', path_to_save=path_dataset_save)\n",
        "        else:\n",
        "            file = open(path_dataset_save+'X.pckl','rb'); X = pickle.load(file); file.close()\n",
        "            file = open(path_dataset_save+'y.pckl','rb'); y = pickle.load(file); file.close()\n",
        "            file = open(path_dataset_save+'image_shape.pckl','rb'); image_shape = pickle.load(file); file.close()\n",
        "\n",
        "    gnb = GaussianNB()\n",
        "    #gnb_mdl = gnb.fit(X,y)\n",
        "    #gnb_pred = gnb_mdl.predict(X)\n",
        "\n",
        "    sfs1 = SFS(gnb, k_features=400, forward=True, floating=False, verbose=2, scoring='accuracy', cv=0)\n",
        "\n",
        "    sfs1 = sfs1.fit(X_train, y_train)\n",
        "    \n",
        "    #to see theselected feature indices at each step\n",
        "    print (\"\\n\\nselected features at each step\\n\")\n",
        "    print (sfs1.subsets_)\n",
        "    print (\"\\n\")\n",
        "\n",
        "    #The indices of the features selected\n",
        "    print (\"\\nindices of the features selected\\n\")\n",
        "    print (sfs1.k_feature_idx_)\n",
        "    print (\"\\n\")\n",
        "\n",
        "    #prediction score for these features\n",
        "    print (\"\\nprediction score for these features\\n\")\n",
        "    print (sfs1.k_score_)\n",
        "    print (\"\\n\")\n",
        "\n",
        "#----------------------------------------------------------------------\n",
        "# functions:\n",
        "\n",
        "# --> good webs for code on plotting manifolds:\n",
        "# https://jakevdp.github.io/PythonDataScienceHandbook/05.10-manifold-learning.html\n",
        "# http://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html\n",
        "\n",
        "###### ----------- Read MNIST dataset:\n",
        "\n",
        "def read_MNIST_dataset(dataset = \"training\", path = \".\"):\n",
        "    # https://gist.github.com/akesling/5358964\n",
        "    \"\"\"\n",
        "    Python function for importing the MNIST data set.  It returns an iterator\n",
        "    of 2-tuples with the first element being the label and the second element\n",
        "    being a numpy.uint8 2D array of pixel data for the given image.\n",
        "    \"\"\"\n",
        "    if dataset is \"training\":\n",
        "        fname_img = os.path.join(path, 'train-images-idx3-ubyte')\n",
        "        fname_lbl = os.path.join(path, 'train-labels-idx1-ubyte')\n",
        "    elif dataset is \"testing\":\n",
        "        fname_img = os.path.join(path, 't10k-images-idx3-ubyte')\n",
        "        fname_lbl = os.path.join(path, 't10k-labels-idx1-ubyte')\n",
        "    else:\n",
        "        print('error.....')\n",
        "    # Load everything in some numpy arrays\n",
        "    with open(fname_lbl, 'rb') as flbl:\n",
        "        magic, num = unpack(\">II\", flbl.read(8))\n",
        "        lbl = np.fromfile(flbl, dtype=np.int8)\n",
        "    with open(fname_img, 'rb') as fimg:\n",
        "        magic, num, rows, cols = unpack(\">IIII\", fimg.read(16))\n",
        "        img = np.fromfile(fimg, dtype=np.uint8).reshape(len(lbl), rows, cols)\n",
        "    get_img = lambda idx: (lbl[idx], img[idx])\n",
        "    # Create an iterator which returns each image in turn\n",
        "    for i in range(len(lbl)):\n",
        "        yield get_img(i)\n",
        "\n",
        "def show_mnist_data(image):\n",
        "    # https://gist.github.com/akesling/5358964\n",
        "    \"\"\"\n",
        "    Render a given numpy.uint8 2D array of pixel data.\n",
        "    \"\"\"\n",
        "    from matplotlib import pyplot\n",
        "    import matplotlib as mpl\n",
        "    fig = pyplot.figure()\n",
        "    ax = fig.add_subplot(1,1,1)\n",
        "    imgplot = ax.imshow(image, cmap=mpl.cm.Greys)\n",
        "    imgplot.set_interpolation('nearest')\n",
        "    ax.xaxis.set_ticks_position('top')\n",
        "    ax.yaxis.set_ticks_position('left')\n",
        "    pyplot.show()\n",
        "\n",
        "###### ----------- Read Facial dataset:\n",
        "\n",
        "def read_image_dataset(dataset_path, imagesType='.png'):\n",
        "    image_list, image_shape = read_images(folder_path=dataset_path, imagesType=imagesType)\n",
        "    number_of_images = len(image_list)\n",
        "    number_of_samples_of_each_class = 10\n",
        "    X = []; y = []\n",
        "    for image_index in range(number_of_images):\n",
        "        class_index = int(image_index / number_of_samples_of_each_class)\n",
        "        image = image_list[image_index]\n",
        "        X.append(image)\n",
        "        y.append(class_index)\n",
        "    X = np.asarray(X)\n",
        "    y = np.asarray(y)\n",
        "    return X, y, image_shape\n",
        "\n",
        "def read_images(folder_path='./', imagesType='.png'):\n",
        "    image_list = []\n",
        "    images_address = folder_path + '*' + imagesType\n",
        "    for filename in natsort(list_=glob.glob(images_address)):\n",
        "        im = Image.open(filename)    # similar to: im = plt.imread(filename)\n",
        "        image_shape = np.asarray(im).shape\n",
        "        im = np.asarray(im).ravel()\n",
        "        image_list.append(im)\n",
        "    return image_list, image_shape\n",
        "\n",
        "def natsort(list_):\n",
        "    \"\"\" for sorting names of files in human-sense \"\"\"\n",
        "    # http://code.activestate.com/recipes/285264-natural-string-sorting/  ---> comment of r8qyfhp02\n",
        "    # decorate\n",
        "    tmp = [ (int(re.search('\\d+', i).group(0)), i) for i in list_ ]\n",
        "    tmp.sort()\n",
        "    # undecorate\n",
        "    return [ i[1] for i in tmp ]\n",
        "\n",
        "###### ----------- Save variables:\n",
        "\n",
        "def save_variable(variable, name_of_variable, path_to_save='./'):\n",
        "    # https://stackoverflow.com/questions/6568007/how-do-i-save-and-restore-multiple-variables-in-python\n",
        "    if not os.path.exists(path_to_save):  # https://stackoverflow.com/questions/273192/how-can-i-create-a-directory-if-it-does-not-exist\n",
        "        os.makedirs(path_to_save)\n",
        "    file_address = path_to_save + name_of_variable + '.pckl'\n",
        "    f = open(file_address, 'wb')\n",
        "    pickle.dump(variable, f)\n",
        "    f.close()\n",
        "\n",
        "###### ----------- Plot images in embedded space:\n",
        "\n",
        "def plot_components(X_projected, images=None, ax=None, image_scale=1, markersize=10, thumb_frac=0.05, cmap='gray'):\n",
        "    # https://jakevdp.github.io/PythonDataScienceHandbook/05.10-manifold-learning.html\n",
        "    ax = ax or plt.gca()\n",
        "    ax.plot(X_projected[:, 0], X_projected[:, 1], '.k', markersize=markersize)\n",
        "    # images = images[:, ::image_scale, ::image_scale]  # downsample the images\n",
        "    # images = imresize(images, (images.shape[0], images.shape[1]*image_scale, images.shape[2]*image_scale))   # downsample the images\n",
        "    images = resize(images, (images.shape[0], images.shape[1]*image_scale, images.shape[2]*image_scale), order=5, preserve_range=True)\n",
        "    if images is not None:\n",
        "        min_dist_2 = (thumb_frac * max(X_projected.max(0) - X_projected.min(0))) ** 2\n",
        "        shown_images = np.array([2 * X_projected.max(0)])\n",
        "        for i in range(X_projected.shape[0]):\n",
        "            dist = np.sum((X_projected[i] - shown_images) ** 2, 1)\n",
        "            if np.min(dist) < min_dist_2:\n",
        "                # don't show points that are too close\n",
        "                continue\n",
        "            shown_images = np.vstack([shown_images, X_projected[i]])\n",
        "            imagebox = offsetbox.AnnotationBbox(\n",
        "                offsetbox.OffsetImage(images[i], cmap=cmap),\n",
        "                                      X_projected[i])\n",
        "            ax.add_artist(imagebox)\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-20640aa04d75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-20640aa04d75>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0msave_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_picked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y_test_picked'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_dataset_save\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_dataset_save\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'X_train_picked.pckl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m                 \u001b[0mX_train_picked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_dataset_save\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'X_test_picked.pckl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/data/X_train_picked.pckl'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "_BOc8GcVbpma",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "outputId": "b7e69744-6c5a-4146-c8d3-b4cc700b2f3d",
        "executionInfo": {
          "status": "error",
          "timestamp": 1531683427856,
          "user_tz": 240,
          "elapsed": 2362,
          "user": {
            "displayName": "Maria Samad",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "104872086100477216762"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Sun Jul 10 03:01:04 2018\n",
        "\n",
        "@author: Samad\n",
        "\"\"\"\n",
        "!pip install mlxtend\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.datasets import load_iris\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "\n",
        "def main():\n",
        "    #iris = load_iris()\n",
        "    #X = iris.data\n",
        "    #y = iris.target\n",
        "    #knn = KNeighborsClassifier(n_neighbors=4)\n",
        "\n",
        "    gnb = GaussianNB()\n",
        "    #gnb_mdl = gnb.fit(X,y)\n",
        "    #gnb_pred = gnb_mdl.predict(X)\n",
        "\n",
        "    sfs1 = SFS(gnb, k_features=3, forward=True, floating=False, verbose=2, scoring='accuracy', cv=0)\n",
        "\n",
        "    sfs1 = sfs1.fit(X_train, y_train)\n",
        "    \n",
        "    #to see theselected feature indices at each step\n",
        "    print (\"\\n\\nselected features at each step\\n\")\n",
        "    print (sfs1.subsets_)\n",
        "    print (\"\\n\")\n",
        "\n",
        "    #The indices of the features selected\n",
        "    print (\"\\nindices of the features selected\\n\")\n",
        "    print (sfs1.k_feature_idx_)\n",
        "    print (\"\\n\")\n",
        "\n",
        "    #prediction score for these features\n",
        "    print (\"\\nprediction score for these features\\n\")\n",
        "    print (sfs1.k_score_)\n",
        "    print (\"\\n\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.6/dist-packages (0.12.0)\r\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (0.19.1)\r\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from mlxtend) (39.1.0)\r\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (2.1.2)\r\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (0.22.0)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (0.19.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (1.14.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.5.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->mlxtend) (2018.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.10.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.11.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-687abadd4323>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-687abadd4323>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0msfs1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSFS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgnb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloating\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0msfs1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msfs1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m#to see theselected feature indices at each step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    }
  ]
}